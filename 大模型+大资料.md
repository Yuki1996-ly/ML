

1.通常在10billion到20个billion能力会有较大的提升，这个时候做COT的效果会比较好，否则是一知半解，效果很差。

<img src="C:\Users\admin\Documents\GitHub\ML\Photoes\image-20230714135135955.png" alt="image-20230714135135955" style="zoom:25%;" />

目前已知最大的模型，里面是很多个模组，也叫moe，每次询问问题也不会调用每一个模组，而是会选择其中一个进行调用，GPT最新的一部分好像就是用的moe

<img src="C:\Users\admin\Documents\GitHub\ML\Photoes\image-20230714135228424.png" alt="image-20230714135228424" style="zoom:25%;" />



2.1如何才能让模型有通识的能力呢，这里有一个测试，大概是30billion的token资料，会有世界知识的能力

<img src="C:\Users\admin\Documents\GitHub\ML\Photoes\image-20230714154915603.png" alt="image-20230714154915603" style="zoom:25%;" />

对于在相同的算力情况下，如何分配模型大小和资料量，这里的一张图，大概有一个最好的比例，1billion的参数，对应20billion的资料量会有最优的效果

<img src="C:\Users\admin\Documents\GitHub\ML\Photoes\image-20230714155523779.png" alt="image-20230714155523779" style="zoom:25%;" />

还有一个使模型效果更好的方式是instruction-tuning，其任务的占比仅仅是预训练模型的百分之0.2，但是能有很好的效果。

1. Fine-tuning（微调）：Fine-tuning是指在预训练阶段之后，使用特定的任务数据对模型进行进一步训练，以使其适应特定任务。在微调过程中，模型通常会保留其预训练阶段的大部分参数，并只更新其中的一小部分参数，以使其能够更好地适应目标任务。Fine-tuning通常需要较少的任务特定数据，因为它能够利用预训练模型的先验知识来进行任务学习。这种技术在自然语言处理任务中非常常见。
2. Instruction-tuning（指令调优）：Instruction-tuning是一种训练技术，旨在通过在任务指令数据上进行训练，使模型能够按照给定的指令生成相应的回复。在Instruction-tuning中，模型接收任务指令的描述和示例作为输入，并通过监督训练的方式学习按照指令执行任务。这种方法可以使模型具备更好的任务执行能力，即使在面对从未见过的任务指令时也能表现出较好的适应性。

简而言之，fine-tuning是指在特定任务上使用少量数据微调模型，而instruction-tuning是通过在任务指令数据上进行监督训练，使模型能够按照指令执行任务。这两种技术在训练大语言模型时都可以起到提升性能的作用。

<img src="C:\Users\admin\Documents\GitHub\ML\Photoes\image-20230714155723582.png" alt="image-20230714155723582" style="zoom:25%;" />